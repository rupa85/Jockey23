{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "path = \"E:\\Deep Learning Datasets-20241106T032755Z-001\\Deep Learning Datasets\\9 Credit Card Dataset\\creditcard.csv\"\n",
        "df = pd.read_csv(path)\n",
        "\n",
        "df = df.drop(['Time','Class'], axis=1)\n",
        "df\n",
        "\n",
        "# Preprocess the data\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "x_train, x_test = train_test_split(df, test_size=0.2)\n",
        "\n",
        "from keras.models import Model, Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout\n",
        "from tensorflow.keras import layers, models\n",
        "\n",
        "encoder = tf.keras.models.Sequential([\n",
        "    layers.Input(shape=(x_train.shape[1],)),\n",
        "    layers.Dense(64, activation='relu'),\n",
        "    layers.Dense(64, activation='relu'),\n",
        "    layers.Dense(20, activation='relu')\n",
        "])\n",
        "\n",
        "decoder = tf.keras.models.Sequential([\n",
        "    layers.Input(shape=(20,)),\n",
        "    layers.Dense(64, activation='relu'),\n",
        "    layers.Dense(64, activation='relu'),\n",
        "    layers.Dense(x_train.shape[1], activation='linear')  # Use linear activation for reconstruction\n",
        "])\n",
        "\n",
        "model = tf.keras.models.Sequential([\n",
        "    encoder,\n",
        "    decoder\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam', loss ='mean_squared_error')\n",
        "\n",
        "history = model.fit(\n",
        "    x_train,\n",
        "    x_train,\n",
        "    validation_data=(x_test,x_test),\n",
        "    epochs=5,\n",
        "    batch_size = 100,\n",
        "    shuffle=True\n",
        ")\n",
        "\n",
        "import seaborn as sns\n",
        "sns.lineplot(model.history.history)\n",
        "\n",
        "predictions = model.predict(x_test)\n",
        "mse = np.mean(np.power(x_test - predictions, 2), axis=1)\n",
        "\n",
        "threshold = np.percentile(mse, 95)  # Adjust the percentile as needed\n",
        "print(threshold)\n",
        "anomalies = mse > threshold\n",
        "\n",
        "# Calculate the number of anomalies\n",
        "num_anomalies = np.sum(anomalies)\n",
        "print(f\"Number of Anomalies: {num_anomalies}\")"
      ],
      "metadata": {
        "id": "7LNnc64Dgs9X"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}