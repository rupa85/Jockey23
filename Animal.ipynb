{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IlwNda6z3lFT"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.applications import MobileNetV2\n",
        "from tensorflow.keras.layers import GlobalAveragePooling2D, Dense\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.preprocessing import image\n",
        "\n",
        "# Set the directory for your dataset\n",
        "dataset_dir = r'E:\\Deep Learning Datasets-20241106T032755Z-001\\Deep Learning Datasets\\Animal 10\\Animal 10\\raw-img'  # Replace with your dataset directory\n",
        "\n",
        "# Set up ImageDataGenerator for training and validation\n",
        "datagen = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    validation_split=0.2  # 20% of the data will be used for validation\n",
        ")\n",
        "\n",
        "# Load training data with 80% split for training and 20% for validation\n",
        "train_generator = datagen.flow_from_directory(\n",
        "    dataset_dir,\n",
        "    target_size=(128, 128),  # Resize images to 128x128 for MobileNetV2\n",
        "    batch_size=32,\n",
        "    class_mode='categorical',\n",
        "    subset='training'  # Use the training subset\n",
        ")\n",
        "\n",
        "validation_generator = datagen.flow_from_directory(\n",
        "    dataset_dir,\n",
        "    target_size=(128, 128),  # Resize images to 128x128 for MobileNetV2\n",
        "    batch_size=32,\n",
        "    class_mode='categorical',\n",
        "    subset='validation'  # Use the validation subset\n",
        ")\n",
        "\n",
        "# Load MobileNetV2 pre-trained on ImageNet and exclude the top layer\n",
        "base_model = MobileNetV2(weights='imagenet', include_top=False, input_shape=(128, 128, 3))\n",
        "base_model.trainable = False  # Freeze the pre-trained layers to prevent them from being trained\n",
        "\n",
        "# Build the model by adding custom layers on top of the base model\n",
        "model = Sequential([\n",
        "    base_model,\n",
        "    GlobalAveragePooling2D(),  # Global Average Pooling layer to reduce spatial dimensions\n",
        "    Dense(1024, activation='relu'),  # Fully connected layer\n",
        "    Dense(len(train_generator.class_indices), activation='softmax')  # Output layer for classification\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model on the dataset\n",
        "history = model.fit(\n",
        "    train_generator,\n",
        "    steps_per_epoch=train_generator.samples // train_generator.batch_size,\n",
        "    epochs=2,  # You can adjust the number of epochs based on your requirements\n",
        "    validation_data=validation_generator,\n",
        "    validation_steps=validation_generator.samples // validation_generator.batch_size\n",
        ")\n",
        "\n",
        "# Evaluate the model on the validation set\n",
        "test_loss, test_acc = model.evaluate(validation_generator)\n",
        "print(f\"Test accuracy: {test_acc}\")\n",
        "\n",
        "# Now let's print actual and predicted labels for a few validation images\n",
        "# Get the filenames and true labels from the validation generator\n",
        "filenames = validation_generator.filenames\n",
        "true_labels = validation_generator.classes\n",
        "\n",
        "# Predict the labels on the validation data\n",
        "predictions = model.predict(validation_generator, steps=validation_generator.samples // validation_generator.batch_size)\n",
        "\n",
        "# Convert predictions to class labels\n",
        "predicted_labels = np.argmax(predictions, axis=1)\n",
        "\n",
        "# Map the integer class labels to the actual class names\n",
        "class_labels = {v: k for k, v in validation_generator.class_indices.items()}\n",
        "\n",
        "# Print actual and predicted labels for a few inputs\n",
        "num_samples = 5  # Print 5 samples\n",
        "for i in range(num_samples):\n",
        "    actual_label = class_labels[true_labels[i]]\n",
        "    predicted_label = class_labels[predicted_labels[i]]\n",
        "    print(f\"Actual Label: {actual_label} | Predicted Label: {predicted_label}\")\n",
        "\n",
        "\n",
        "    import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.applications import MobileNetV2\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import GlobalAveragePooling2D, Dense\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras import mixed_precision\n",
        "\n",
        "# Set mixed precision training\n",
        "policy = mixed_precision.Policy('mixed_float16')\n",
        "mixed_precision.set_global_policy(policy)\n",
        "\n",
        "# Load MobileNetV2 model with ImageNet weights and excluding the top layers\n",
        "# Modify the model's input shape to (128, 128, 3)\n",
        "base_model = MobileNetV2(weights='imagenet', include_top=False, input_shape=(128, 128, 3))\n",
        "base_model.trainable = False\n",
        "\n",
        "# Add custom layers for the specific task\n",
        "x = base_model.output\n",
        "x = GlobalAveragePooling2D()(x)\n",
        "x = Dense(128, activation='relu')(x)\n",
        "predictions = Dense(10, activation='softmax')(x)\n",
        "\n",
        "# Create the model\n",
        "model = Model(inputs=base_model.input, outputs=predictions)\n",
        "\n",
        "# Compile the model with Adam optimizer and categorical cross-entropy loss\n",
        "model.compile(optimizer=Adam(learning_rate=0.001),\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "\n",
        "# Data augmentation and rescaling\n",
        "datagen = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    validation_split=0.2,\n",
        "    horizontal_flip=True\n",
        "    # You can experiment with other augmentations like zoom_range and shear_range here.\n",
        ")\n",
        "\n",
        "# Create the training data generator\n",
        "train_generator = datagen.flow_from_directory(\n",
        "    r\"E:\\Deep Learning Datasets-20241106T032755Z-001\\Deep Learning Datasets\\Animal 10\\Animal 10\\raw-img\",\n",
        "    target_size=(128, 128),  # Lower resolution for faster training\n",
        "    batch_size=32,\n",
        "    class_mode='categorical',\n",
        "    subset='training'\n",
        ")\n",
        "\n",
        "validation_generator = datagen.flow_from_directory(\n",
        "    r\"E:\\Deep Learning Datasets-20241106T032755Z-001\\Deep Learning Datasets\\Animal 10\\Animal 10\\raw-img\",\n",
        "    target_size=(128, 128),  # Lower resolution for faster training\n",
        "    batch_size=32,\n",
        "    class_mode='categorical',\n",
        "    subset='validation'\n",
        ")\n",
        "\n",
        "# Train the model (reduced epochs for faster feedback)\n",
        "history = model.fit(\n",
        "    train_generator,\n",
        "    validation_data=validation_generator,\n",
        "    epochs=3,  # You can try a few more epochs if needed\n",
        "    batch_size=64  # Increased batch size (adjust according to GPU memory)\n",
        ")\n",
        "\n",
        "\n",
        "# Evaluate the model on validation data\n",
        "test_loss, test_acc = model.evaluate(validation_generator)\n",
        "\n",
        "print(\"Test Loss:\", test_loss)\n",
        "print(\"\\nTest Accuracy:\", test_acc)\n",
        "\n",
        "# Get predictions and plot results\n",
        "x_val, y_val = next(validation_generator)\n",
        "predictions = model.predict(x_val)\n",
        "predicted_labels = np.argmax(predictions, axis=1)\n",
        "\n",
        "# Display some sample results\n",
        "n = 5\n",
        "class_labels = list(train_generator.class_indices.keys())\n",
        "plt.figure(figsize=(5, 15))\n",
        "for i in range(n):\n",
        "    plt.subplot(n, 1, i + 1)\n",
        "    plt.imshow(x_val[i])\n",
        "    actual_label = class_labels[np.argmax(y_val[i])]\n",
        "    predicted_label = class_labels[predicted_labels[i]]\n",
        "    plt.title(f\"Actual={actual_label}\\nPredicted={predicted_label}\")\n",
        "    plt.axis(\"off\")\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    }
  ]
}